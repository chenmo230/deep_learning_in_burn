{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde27d82-a614-4a19-993d-bb1696f1f683",
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep burn = {version = \"0.12.1\", features = [\"ndarray\", \"wgpu\", \"candle\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f65b6b-3fc6-4a1e-9f33-b512ad2952ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "/// maybe you will meet some trouble in this step,\n",
    "/// this info maybe help you：\n",
    "/// 1. check if it is installed `hdf5` in your computer, in mac os: brew install hdfs\n",
    "/// 2. check `HDF5_LIB` and `HDF5_INCLUDE`; you can run commend: `find / -name hdf5` to find it\n",
    "/// 3. check if your computer is install `cmake`. if not, install it. in mac os: brew install cmake\n",
    ":dep hdf5 = { version = \"0.8.1\", features = [\"blosc\", \"lzf\"]}\n",
    ":dep hdf5-sys = { version = \"0.8.1\", features = [\"static\", \"zlib\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c92dbc9-794c-4c68-80a4-383a3d3c881f",
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep ndarray = \"0.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89f6b00-c833-4cfb-90eb-9174515a9a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "burn = {version = \"0.12.1\", features = [\"ndarray\", \"wgpu\", \"candle\"]}\n",
       "hdf5 = { version = \"0.8.1\", features = [\"blosc\", \"lzf\"]}\n",
       "hdf5-sys = { version = \"0.8.1\", features = [\"static\", \"zlib\"]}\n",
       "ndarray = \"0.15.0\"\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ":show_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c640033-0593-4e9d-821b-fe89a959c790",
   "metadata": {},
   "source": [
    "### 1. load_dataset from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8c2353-c407-4683-af76-4d594d504a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "use hdf5::{File};\n",
    "use ndarray::{Array1, Array4};\n",
    "\n",
    "fn load_dataset() -> (Array4<f32>, Array1<f32>, Array4<f32>, Array1<f32>) {\n",
    "    // open HDF5 file\n",
    "    let train_file = File::open(\"datasets/train_catvnoncat.h5\").unwrap();\n",
    "    // read dataset\n",
    "    let train_x_dataset = train_file.dataset(\"train_set_x\").unwrap();\n",
    "    let train_y_dataset = train_file.dataset(\"train_set_y\").unwrap();\n",
    "\n",
    "    let test_file = File::open(\"datasets/test_catvnoncat.h5\").unwrap();\n",
    "    let test_x_dataset = test_file.dataset(\"test_set_x\").unwrap();\n",
    "    let test_y_dataset = test_file.dataset(\"test_set_y\").unwrap();\n",
    "\n",
    "    // change dataset to ndarray\n",
    "    let train_x_ndarray: Array4<f32> = train_x_dataset.read_slice((.., .., .., ..)).unwrap();\n",
    "    let train_y_ndarray: Array1<f32> = train_y_dataset.read_slice(..).unwrap();\n",
    "\n",
    "    let test_x_ndarray: Array4<f32> = test_x_dataset.read_slice((.., .., .., ..)).unwrap();\n",
    "    let test_y_ndarray: Array1<f32> = test_y_dataset.read_slice(..).unwrap();\n",
    "\n",
    "    return (train_x_ndarray, train_y_ndarray, test_x_ndarray, test_y_ndarray)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c27bd-3980-4210-b9eb-194a3658b765",
   "metadata": {},
   "source": [
    "### 2. load data from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b282557b-61c3-4bdc-bce6-f42a335f7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_ndarray.shape: [209, 64, 64, 3]\n",
      "train_y_ndarray.shape: [209]\n",
      "test_x_ndarray.shape: [50, 64, 64, 3]\n",
      "test_y_ndarray.shape: [50]\n"
     ]
    }
   ],
   "source": [
    "let (train_x_ndarray, train_y_ndarray, test_x_ndarray, test_y_ndarray) = load_dataset();\n",
    "println!(\"train_x_ndarray.shape: {:?}\", train_x_ndarray.shape());\n",
    "println!(\"train_y_ndarray.shape: {:?}\", train_y_ndarray.shape());\n",
    "\n",
    "println!(\"test_x_ndarray.shape: {:?}\", test_x_ndarray.shape());\n",
    "println!(\"test_y_ndarray.shape: {:?}\", test_y_ndarray.shape());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf48eda-56a3-44ad-9ce0-d4047435712e",
   "metadata": {},
   "source": [
    "### 3. reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114b58c6-ce48-4c2f-a688-f6ad88ca124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_ndarray.shape: [209, 12288]\n",
      "train_y_ndarray.shape: [209, 1]\n",
      "test_x_ndarray.shape: [50, 12288]\n",
      "test_y_ndarray.shape: [50, 1]\n"
     ]
    }
   ],
   "source": [
    "// reshape data\n",
    "let train_numbers: usize = train_x_ndarray.shape()[0];\n",
    "let features = 64 * 64 * 3;\n",
    "let train_x_ndarray = train_x_ndarray.clone().into_shape((train_numbers, features)).unwrap();\n",
    "let train_y_ndarray = train_y_ndarray.clone().into_shape((train_numbers, 1)).unwrap();\n",
    "println!(\"train_x_ndarray.shape: {:?}\", train_x_ndarray.shape());\n",
    "println!(\"train_y_ndarray.shape: {:?}\", train_y_ndarray.shape());\n",
    "\n",
    "let test_numbers: usize = test_x_ndarray.shape()[0];\n",
    "let test_x_ndarray = test_x_ndarray.clone().into_shape((test_numbers, features)).unwrap();\n",
    "let test_y_ndarray = test_y_ndarray.clone().into_shape((test_numbers, 1)).unwrap();\n",
    "println!(\"test_x_ndarray.shape: {:?}\", test_x_ndarray.shape());\n",
    "println!(\"test_y_ndarray.shape: {:?}\", test_y_ndarray.shape());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ac6ba-0f19-4b1b-8c55-bf2fd65b21b6",
   "metadata": {},
   "source": [
    "### 4. convert ndarray to burn tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bcc0996-4039-420e-87c7-7e00cbe76639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_tensor ======: Tensor {\n",
      "  data:\n",
      "[[17.0, 31.0, 56.0, ..., 0.0, 0.0, 0.0],\n",
      " [196.0, 192.0, 190.0, ..., 82.0, 80.0, 81.0],\n",
      " [82.0, 71.0, 68.0, ..., 138.0, 141.0, 142.0],\n",
      " ...\n",
      " [143.0, 155.0, 165.0, ..., 85.0, 107.0, 149.0],\n",
      " [22.0, 24.0, 23.0, ..., 4.0, 5.0, 0.0],\n",
      " [8.0, 28.0, 53.0, ..., 0.0, 0.0, 0.0]],\n",
      "  shape:  [209, 12288],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "train_y_tensor.shape ======: Shape { dims: [209, 1] }\n",
      "test_x_tensor ======: Tensor {\n",
      "  data:\n",
      "[[158.0, 104.0, 83.0, ..., 173.0, 128.0, 110.0],\n",
      " [115.0, 110.0, 111.0, ..., 171.0, 176.0, 186.0],\n",
      " [255.0, 253.0, 254.0, ..., 133.0, 101.0, 121.0],\n",
      " ...\n",
      " [41.0, 47.0, 84.0, ..., 183.0, 141.0, 116.0],\n",
      " [18.0, 18.0, 16.0, ..., 144.0, 137.0, 108.0],\n",
      " [133.0, 163.0, 75.0, ..., 5.0, 22.0, 5.0]],\n",
      "  shape:  [50, 12288],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "test_y_tensor.shape ======: Shape { dims: [50, 1] }\n"
     ]
    }
   ],
   "source": [
    "use burn::tensor::{Data, Shape, Tensor};\n",
    "use burn::backend::{NdArray};\n",
    "use burn::tensor::backend::Backend;\n",
    "use ndarray::prelude::{ArrayBase, Dim};\n",
    "\n",
    "type MyBackend = NdArray; \n",
    "\n",
    "fn ndarray_to_tensor<B: Backend>(ndarray: ArrayBase<ndarray::OwnedRepr<f32>, Dim<[usize; 2]>>) -> Tensor<B, 2>\n",
    "    where Data<<B as Backend>::FloatElem, 1>: From<burn::tensor::Data<f32, 1>> {\n",
    "\n",
    "    let device = Default::default();\n",
    "    let m = ndarray.shape()[0];\n",
    "    let features = ndarray.shape()[1];\n",
    "\n",
    "\n",
    "    let mut result_tensor: Tensor<B, 2> = Tensor::zeros([m, features], &device);\n",
    "    let shape = [features];  \n",
    "\n",
    "    let mut i = 0;\n",
    "    for row in ndarray.clone().rows() {\n",
    "        let row_vec: Vec<f32> = row.to_vec();\n",
    "        \n",
    "        let data = Data::new(row_vec, Shape::new(shape));\n",
    "        let row_tensor = Tensor::<B, 1>::from_data(data, &device).reshape([1, features]);\n",
    "        \n",
    "        result_tensor = result_tensor.slice_assign([i..i+1], row_tensor);\n",
    "        i += 1;\n",
    "    }\n",
    "\n",
    "    result_tensor\n",
    "}\n",
    "\n",
    "// convert train_x_ndarray to burn tensor\n",
    "let train_x_tensor: Tensor<MyBackend, 2> = ndarray_to_tensor(train_x_ndarray.clone());\n",
    "// convert train_y_ndarray to burn tensor\n",
    "let train_y_tensor: Tensor<MyBackend, 2> = ndarray_to_tensor(train_y_ndarray.clone());\n",
    "\n",
    "// convert test_x_ndarray to burn tensor\n",
    "let test_x_tensor: Tensor<MyBackend, 2> = ndarray_to_tensor(test_x_ndarray.clone());\n",
    "// convert test_y_ndarray to burn tensor\n",
    "let test_y_tensor: Tensor<MyBackend, 2> = ndarray_to_tensor(test_y_ndarray.clone());\n",
    "\n",
    "println!(\"train_x_tensor ======: {}\", train_x_tensor);\n",
    "println!(\"train_y_tensor.shape ======: {:?}\", train_y_tensor.shape());\n",
    "println!(\"test_x_tensor ======: {}\", test_x_tensor);\n",
    "println!(\"test_y_tensor.shape ======: {:?}\", test_y_tensor.shape());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ec86c-3993-413a-9bc0-a1089aefbb0a",
   "metadata": {},
   "source": [
    "### 5. Data standardization processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45cad4ee-0e32-47ab-9fbc-77f3013a2c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_tensor ======: Tensor {\n",
      "  data:\n",
      "[[0.06666667, 0.12156863, 0.21960784, ..., 0.0, 0.0, 0.0],\n",
      " [0.76862746, 0.7529412, 0.74509805, ..., 0.32156864, 0.3137255, 0.31764707],\n",
      " [0.32156864, 0.2784314, 0.26666668, ..., 0.5411765, 0.5529412, 0.5568628],\n",
      " ...\n",
      " [0.56078434, 0.60784316, 0.64705884, ..., 0.33333334, 0.41960785, 0.58431375],\n",
      " [0.08627451, 0.09411765, 0.09019608, ..., 0.015686275, 0.019607844, 0.0],\n",
      " [0.03137255, 0.10980392, 0.20784314, ..., 0.0, 0.0, 0.0]],\n",
      "  shape:  [209, 12288],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "test_x_tensor ======: Tensor {\n",
      "  data:\n",
      "[[158.0, 104.0, 83.0, ..., 173.0, 128.0, 110.0],\n",
      " [115.0, 110.0, 111.0, ..., 171.0, 176.0, 186.0],\n",
      " [255.0, 253.0, 254.0, ..., 133.0, 101.0, 121.0],\n",
      " ...\n",
      " [41.0, 47.0, 84.0, ..., 183.0, 141.0, 116.0],\n",
      " [18.0, 18.0, 16.0, ..., 144.0, 137.0, 108.0],\n",
      " [133.0, 163.0, 75.0, ..., 5.0, 22.0, 5.0]],\n",
      "  shape:  [50, 12288],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "let train_x_tensor = train_x_tensor.div_scalar(255.0);\n",
    "let test_y_tensor = test_y_tensor.div_scalar(255.0);\n",
    "\n",
    "println!(\"train_x_tensor ======: {}\", train_x_tensor);\n",
    "println!(\"test_x_tensor ======: {}\", test_x_tensor);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e450a-cb5a-45a8-b1a7-449605976963",
   "metadata": {},
   "source": [
    "### 6. sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47bebe0d-824d-4329-9e20-97db028e2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn basic_sigmoid<B: Backend, const D: usize>(x: Tensor<B, D>) -> Tensor<B, D> {\n",
    "    let ones = x.ones_like();\n",
    "    return ones.clone() / (ones.clone() + (-x).exp());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb00abb-6cc0-4d09-8c78-3cf067a1707d",
   "metadata": {},
   "source": [
    "### 7. initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a0a8dd3-5a3d-411d-b13d-88082c9e1571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_tensor ======: Tensor {\n",
      "  data:\n",
      "[[0.0],\n",
      " [0.0],\n",
      " [0.0],\n",
      " ...\n",
      " [0.0],\n",
      " [0.0],\n",
      " [0.0]],\n",
      "  shape:  [12288, 1],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "b ======: 0\n"
     ]
    }
   ],
   "source": [
    "fn initialize_with_zeros<B: Backend, const D: usize>(shape: [usize; D]) -> (Tensor<B, D>, f32) {\n",
    "    let device = Default::default();\n",
    "    // \n",
    "    let w_tensor = Tensor::<B, D>::zeros(shape, &device);\n",
    "    let b: f32 = 0.0;\n",
    "\n",
    "    return (w_tensor, b);\n",
    "}\n",
    "\n",
    "// test initialize_with_zeros function\n",
    "let (w, b) = initialize_with_zeros::<MyBackend, 2>([features, 1]);\n",
    "println!(\"w_tensor ======: {}\", w);\n",
    "println!(\"b ======: {}\", b);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43794b3-f942-48fc-9b04-878eb0602323",
   "metadata": {},
   "source": [
    "### 8. forward and backward propagation\n",
    "compute dw,db and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5816f03a-216f-40ec-b007-029326b8c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw ======: Tensor {\n",
      "  data:\n",
      "[[0.047208935],\n",
      " [0.06299839],\n",
      " [0.049235366],\n",
      " ...\n",
      " [0.05074585],\n",
      " [0.062125903],\n",
      " [0.03245145]],\n",
      "  shape:  [12288, 1],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "db ======: 0.1555024\n",
      "cost ======: 0.6931474\n"
     ]
    }
   ],
   "source": [
    "/// compute dw,db and cost\n",
    "/// params:\n",
    "///     w: weights, shape: (num_features, 1)\n",
    "///     b: bias, f32\n",
    "///     X: x data, shape: (m, num_features)\n",
    "///     Y: labels, shape:(m, 1)\n",
    "/// return:\n",
    "///      dw, db, cost\n",
    "fn propagate<B: Backend, const D: usize>(w: Tensor<B, D>, b: f32, train_x: Tensor<B, D>, train_y: Tensor<B, D>) -> (Tensor<B, D>, f32, f32)\n",
    "    where B: Backend<FloatElem = f32> {\n",
    "    let m = train_x.dims()[0];\n",
    "\n",
    "    // forword\n",
    "    // X: (m, num_features), w: (num_features, 1), z: (m, 1)\n",
    "    let z = train_x.clone().matmul(w).add_scalar(b);\n",
    "    // A: (m, 1)\n",
    "    let a = basic_sigmoid(z);\n",
    "\n",
    "    // cost: f32\n",
    "    // cost = (-1 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    // Y * np.log(A)\n",
    "    let y_is_set = train_y.clone().mul(a.clone().log());\n",
    "    // (1 - Y) * np.log(1 - A)\n",
    "    let ones = train_y.ones_like();\n",
    "    let y_is_not_set = (ones.clone() - train_y.clone()).mul((ones.clone() - a.clone()).log());\n",
    "    let sum = (y_is_set + y_is_not_set).sum().into_scalar();\n",
    "    let cost: f32 = (-1f32/(m as f32)) * sum;\n",
    "\n",
    "\n",
    "    // backward\n",
    "    // dz.shape: (m, 1)\n",
    "    let dz: Tensor<B, D> = a.clone() - train_y.clone();\n",
    "    // dw = (1 / m) * np.dot(X.T, dz)\n",
    "    // dw.shape: (num_features, 1), X.T: (num_features, m), dz: (m, 1)\n",
    "    let dw: Tensor<B, D> =  train_x.clone().transpose().matmul(dz.clone()).mul_scalar(1f32/(m as f32));\n",
    "\n",
    "    // db = (1 / m) * np.sum(dz)\n",
    "    let db: f32 = (1f32/(m as f32)) * dz.clone().sum().into_scalar();\n",
    "\n",
    "    return (dw, db, cost);\n",
    "}\n",
    "\n",
    "\n",
    "// test propagate function\n",
    "let (dw, db, cost) = propagate::<MyBackend, 2>(w.clone(), b.clone(), train_x_tensor.clone(), train_y_tensor.clone());\n",
    "println!(\"dw ======: {}\", dw);\n",
    "println!(\"db ======: {}\", db);\n",
    "println!(\"cost ======: {}\", cost);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e186ee-b7fb-478d-abda-14d84b0bdb87",
   "metadata": {},
   "source": [
    "### 9. optimizing process\n",
    "update w and b, and save cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a00a49fb-1108-4b1d-8699-a4aae22a8701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost result 0: 0.6931474\n",
      "cost result 100: 0.8121615\n",
      "cost result 200: 0.97539\n",
      "w_tensor ======: Tensor {\n",
      "  data:\n",
      "[[0.0060156994],\n",
      " [-0.012305489],\n",
      " [-0.0060849716],\n",
      " ...\n",
      " [-0.0090845805],\n",
      " [-0.018362092],\n",
      " [0.0073324963]],\n",
      "  shape:  [12288, 1],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "b ======: -0.0053707436\n"
     ]
    }
   ],
   "source": [
    "/// update w and b, and save cost\n",
    "/// params:\n",
    "///     w: weights, shape: (num_features, 1)\n",
    "///     b: bias, f32\n",
    "///     train_x: x data, shape: (m, num_features)\n",
    "///     train_y: labels, shape:(m, 1)\n",
    "///     num_iterations\n",
    "///     learning_rate\n",
    "/// return:\n",
    "///      w, b, costs\n",
    "fn optimize<B: Backend, const D: usize>(w: Tensor<B, D>,\n",
    "                                        b: f32, \n",
    "                                        train_x: Tensor<B, D>,\n",
    "                                        train_y: Tensor<B, D>,\n",
    "                                        num_iterations: usize,\n",
    "                                        learning_rate: f32) -> (Tensor<B, D>, f32, Vec<f32>)\n",
    "    where B: Backend<FloatElem = f32> {\n",
    "    let mut costs: Vec<f32> = vec![];\n",
    "    let mut w = w;\n",
    "    let mut b = b;\n",
    "\n",
    "    for i in 0..num_iterations {\n",
    "        let (dw, db, cost) = propagate::<B, D>(w.clone(), b, train_x.clone(), train_y.clone());\n",
    "\n",
    "        w = w - dw.mul_scalar(learning_rate);\n",
    "        b = b - learning_rate * db;\n",
    "\n",
    "        if i % 100 == 0 {\n",
    "            costs.push(cost);\n",
    "            println!(\"cost result {}: {}\", i, cost);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return (w, b, costs);\n",
    "}\n",
    "\n",
    "let (w, b, costs) = optimize::<MyBackend, 2>(w.clone(), b, train_x_tensor.clone(), train_y_tensor.clone(), 201, 0.01);\n",
    "println!(\"w_tensor ======: {}\", w);\n",
    "println!(\"b ======: {}\", b);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454852c-542e-41dd-9eb0-a962145ae1e1",
   "metadata": {},
   "source": [
    "### 10. predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5735ef8-eecc-4bd0-be9e-c10c3667ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_prediction.shape ======: Shape { dims: [209, 1] }\n"
     ]
    }
   ],
   "source": [
    "use burn::tensor::{Bool};\n",
    "\n",
    "/// params：\n",
    "///         w: weights, shape: (num_features, 1)\n",
    "///         b: bias\n",
    "///         x: x data, shape: (m, num_features)\n",
    "/// Returns:\n",
    "///         y_prediction: shape: (m, 1) \n",
    "fn predict<B: Backend, const D: usize>(w: Tensor<B, D>,b: f32, x: Tensor<B, D>) -> Tensor<B, 2> {\n",
    "    let m = x.dims()[0];\n",
    "\n",
    "    // forward\n",
    "    // x: (m, num_features), w: (num_features, 1), z: (m, 1)\n",
    "    // z = (np.dot(X, w) + b).reshape(m, 1)\n",
    "    let z = x.matmul(w).add_scalar(b).reshape([m, 1]);\n",
    "    // a shape: (m, 1)\n",
    "    let a = basic_sigmoid(z);\n",
    "\n",
    "    let half = a.ones_like().mul_scalar(0.5);\n",
    "    let y_prediction = a.greater_equal(half).float();\n",
    "\n",
    "    return y_prediction;\n",
    "}\n",
    "\n",
    "\n",
    "// test predict function\n",
    "let y_prediction = predict::<MyBackend, 2>(w.clone(), b, train_x_tensor.clone());\n",
    "println!(\"y_prediction.shape ======: {:?}\", y_prediction.shape());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759a52b-c484-41a2-8da5-3a8d202c36c8",
   "metadata": {},
   "source": [
    "### 11. implement all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae99873e-1360-4b42-9eae-ff1fa3d4b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost result 0: 0.6931474\n",
      "cost result 100: 0.58450836\n",
      "cost result 200: 0.46694905\n",
      "cost result 300: 0.37600684\n",
      "cost result 400: 0.33146328\n",
      "cost result 500: 0.30327308\n",
      "cost result 600: 0.27987957\n",
      "cost result 700: 0.26004213\n",
      "cost result 800: 0.24294068\n",
      "cost result 900: 0.22800422\n",
      "cost result 1000: 0.2148195\n",
      "cost result 1100: 0.2030782\n",
      "cost result 1200: 0.19254427\n",
      "cost result 1300: 0.18303332\n",
      "cost result 1400: 0.17439859\n",
      "cost result 1500: 0.16652139\n",
      "cost result 1600: 0.15930451\n",
      "cost result 1700: 0.15266731\n",
      "cost result 1800: 0.14654222\n",
      "cost result 1900: 0.14087208\n",
      "train data accuracy: Tensor {\n",
      "  data:\n",
      "[0.9904306],\n",
      "  shape:  [1],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n",
      "test  data accuracy: Tensor {\n",
      "  data:\n",
      "[0.24],\n",
      "  shape:  [1],\n",
      "  device:  Cpu,\n",
      "  backend:  \"ndarray\",\n",
      "  kind:  \"Float\",\n",
      "  dtype:  \"f32\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "let num_features = train_x_tensor.dims()[1];\n",
    "\n",
    "let (w, b) = initialize_with_zeros::<MyBackend, 2>([num_features, 1]);\n",
    "\n",
    "// get w and b\n",
    "let (w, b, costs) = optimize::<MyBackend, 2>(w, b, train_x_tensor.clone(), train_y_tensor.clone(), 2000, 0.005);\n",
    "\n",
    "// predict\n",
    "let y_prediction_train = predict::<MyBackend, 2>(w.clone(), b, train_x_tensor.clone());\n",
    "let y_prediction_test = predict::<MyBackend, 2>(w.clone(), b, test_x_tensor.clone());\n",
    "\n",
    "// print accuracy\n",
    "println!(\"train data accuracy: {}\", y_prediction_train.equal(train_y_tensor).float().mean());\n",
    "println!(\"test  data accuracy: {}\", y_prediction_test.equal(test_y_tensor).float().mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d260a02-311d-419a-8fe6-7fd9dbe162f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
